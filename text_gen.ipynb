{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0.post100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('input.txt', 'r').read()\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data)):\n",
    "#     data[i] = data[i].strip(\"\\n\").lower()   \n",
    "# # remove all elements in data which are empty strings\n",
    "# data = list(filter(None, data))\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# for name in data:\n",
    "#     for word in name.split():\n",
    "#         words.append(word)\n",
    "# len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: '\\n',\n",
       "  1: ' ',\n",
       "  2: '!',\n",
       "  3: '$',\n",
       "  4: '&',\n",
       "  5: \"'\",\n",
       "  6: ',',\n",
       "  7: '-',\n",
       "  8: '.',\n",
       "  9: '3',\n",
       "  10: ':',\n",
       "  11: ';',\n",
       "  12: '?',\n",
       "  13: 'A',\n",
       "  14: 'B',\n",
       "  15: 'C',\n",
       "  16: 'D',\n",
       "  17: 'E',\n",
       "  18: 'F',\n",
       "  19: 'G',\n",
       "  20: 'H',\n",
       "  21: 'I',\n",
       "  22: 'J',\n",
       "  23: 'K',\n",
       "  24: 'L',\n",
       "  25: 'M',\n",
       "  26: 'N',\n",
       "  27: 'O',\n",
       "  28: 'P',\n",
       "  29: 'Q',\n",
       "  30: 'R',\n",
       "  31: 'S',\n",
       "  32: 'T',\n",
       "  33: 'U',\n",
       "  34: 'V',\n",
       "  35: 'W',\n",
       "  36: 'X',\n",
       "  37: 'Y',\n",
       "  38: 'Z',\n",
       "  39: 'a',\n",
       "  40: 'b',\n",
       "  41: 'c',\n",
       "  42: 'd',\n",
       "  43: 'e',\n",
       "  44: 'f',\n",
       "  45: 'g',\n",
       "  46: 'h',\n",
       "  47: 'i',\n",
       "  48: 'j',\n",
       "  49: 'k',\n",
       "  50: 'l',\n",
       "  51: 'm',\n",
       "  52: 'n',\n",
       "  53: 'o',\n",
       "  54: 'p',\n",
       "  55: 'q',\n",
       "  56: 'r',\n",
       "  57: 's',\n",
       "  58: 't',\n",
       "  59: 'u',\n",
       "  60: 'v',\n",
       "  61: 'w',\n",
       "  62: 'x',\n",
       "  63: 'y',\n",
       "  64: 'z'},\n",
       " {'\\n': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  '$': 3,\n",
       "  '&': 4,\n",
       "  \"'\": 5,\n",
       "  ',': 6,\n",
       "  '-': 7,\n",
       "  '.': 8,\n",
       "  '3': 9,\n",
       "  ':': 10,\n",
       "  ';': 11,\n",
       "  '?': 12,\n",
       "  'A': 13,\n",
       "  'B': 14,\n",
       "  'C': 15,\n",
       "  'D': 16,\n",
       "  'E': 17,\n",
       "  'F': 18,\n",
       "  'G': 19,\n",
       "  'H': 20,\n",
       "  'I': 21,\n",
       "  'J': 22,\n",
       "  'K': 23,\n",
       "  'L': 24,\n",
       "  'M': 25,\n",
       "  'N': 26,\n",
       "  'O': 27,\n",
       "  'P': 28,\n",
       "  'Q': 29,\n",
       "  'R': 30,\n",
       "  'S': 31,\n",
       "  'T': 32,\n",
       "  'U': 33,\n",
       "  'V': 34,\n",
       "  'W': 35,\n",
       "  'X': 36,\n",
       "  'Y': 37,\n",
       "  'Z': 38,\n",
       "  'a': 39,\n",
       "  'b': 40,\n",
       "  'c': 41,\n",
       "  'd': 42,\n",
       "  'e': 43,\n",
       "  'f': 44,\n",
       "  'g': 45,\n",
       "  'h': 46,\n",
       "  'i': 47,\n",
       "  'j': 48,\n",
       "  'k': 49,\n",
       "  'l': 50,\n",
       "  'm': 51,\n",
       "  'n': 52,\n",
       "  'o': 53,\n",
       "  'p': 54,\n",
       "  'q': 55,\n",
       "  'r': 56,\n",
       "  's': 57,\n",
       "  't': 58,\n",
       "  'u': 59,\n",
       "  'v': 60,\n",
       "  'w': 61,\n",
       "  'x': 62,\n",
       "  'y': 63,\n",
       "  'z': 64})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars = list(set(''.join(data)))\n",
    "unique_chars.sort()\n",
    "vocab_dict = {i:ch for i, ch in enumerate(unique_chars)}\n",
    "vocab_dict_inv = {ch:i for i, ch in enumerate(unique_chars)}\n",
    "vocab_dict, vocab_dict_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "# X, Y = [], []\n",
    "# for w in words[:]:\n",
    "#   context = [0] * block_size\n",
    "#   for ch in w + ' ':\n",
    "#     ix = vocab_dict_inv[ch]\n",
    "#     X.append(context)\n",
    "#     Y.append(ix)\n",
    "#     print(''.join(vocab_dict[i] for i in context), '--->', vocab_dict[ix])\n",
    "#     context = context[1:] + [ix] # crop and append\n",
    "# X = torch.tensor(X)\n",
    "# Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "block_size = 8\n",
    "for i in range(0, len(data)-block_size, 1):\n",
    "    X.append([vocab_dict_inv[ch] for ch in data[i:i+block_size]])\n",
    "    Y.append(vocab_dict_inv[data[i+block_size]])\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Ci ---> t\n"
     ]
    }
   ],
   "source": [
    "for i in range(block_size):\n",
    "    print(''.join(vocab_dict[X[0][i].item()]), end='')\n",
    "print(' --->', vocab_dict[Y[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115386, 8]), torch.int64, torch.Size([1115386]), torch.int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer for the context\n",
    "\n",
    "emb_dim = 8\n",
    "emb = torch.nn.Embedding(len(vocab_dict), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 6.5535e-01, -2.9290e-01,  1.9644e+00,  3.2271e-01,  1.2357e-01,\n",
       "          7.7596e-02, -2.3553e+00, -1.1443e+00],\n",
       "        [-1.6517e+00,  4.9936e-01,  9.9318e-03, -1.1640e+00,  1.3046e+00,\n",
       "          7.2440e-01,  1.2430e+00, -6.4539e-01],\n",
       "        [ 1.0337e-01, -1.0138e+00, -2.0220e-01, -1.7904e+00,  1.0182e-01,\n",
       "         -3.6816e-01, -2.0775e+00,  3.7345e-01],\n",
       "        [ 1.6400e-01,  1.4959e+00,  6.7536e-01,  8.7700e-01,  5.2813e-01,\n",
       "         -3.3672e-01,  2.6096e-01, -9.6487e-01],\n",
       "        [ 7.4527e-01,  2.1738e-01,  3.4836e-01, -9.0853e-01, -1.4168e+00,\n",
       "         -7.4028e-01, -1.9314e+00, -3.4593e-01],\n",
       "        [ 4.5571e-01,  1.1409e+00,  7.3276e-01,  7.9037e-01, -7.8775e-01,\n",
       "          2.4492e-01,  2.0399e+00,  2.0985e-01],\n",
       "        [ 7.1690e-02, -7.9993e-01, -6.3169e-01,  5.5790e-01,  2.1350e-01,\n",
       "          2.8275e-01, -6.7363e-01, -1.2461e-01],\n",
       "        [ 1.9392e+00,  4.6576e-01,  1.3959e+00, -8.6556e-01,  4.7334e-01,\n",
       "         -3.8289e-01,  5.5716e-01,  1.4819e+00],\n",
       "        [-8.3738e-01,  1.0044e+00,  1.2420e-01, -4.1780e-01,  9.8048e-01,\n",
       "         -3.8406e-01,  2.4527e-01,  1.6152e-02],\n",
       "        [-5.3244e-02, -8.5550e-01,  1.3675e+00, -9.2153e-01, -1.8354e+00,\n",
       "         -1.4364e-01,  5.4747e-01, -3.4326e-01],\n",
       "        [ 1.3914e-01,  3.3187e-01,  5.8342e-01,  3.4758e-01, -5.7517e-01,\n",
       "         -8.0643e-02,  9.0148e-01, -6.2832e-02],\n",
       "        [-1.2586e+00, -1.8150e+00, -2.0244e-01, -6.0554e-01,  2.3946e+00,\n",
       "          1.7257e+00,  2.4686e+00, -4.2347e-01],\n",
       "        [-1.4226e+00, -8.7834e-01, -2.8152e+00,  6.3396e-01,  7.9965e-01,\n",
       "         -7.4562e-01, -7.3433e-01, -2.9452e-02],\n",
       "        [-1.2858e+00,  1.6837e+00, -8.9407e-02,  3.0536e-01, -7.2577e-01,\n",
       "          1.1688e+00,  1.9997e+00, -7.9956e-01],\n",
       "        [ 4.6595e-01, -6.1911e-01,  1.5183e-01, -8.2320e-01, -4.4369e-01,\n",
       "          1.8754e+00, -2.3707e-01, -1.0250e+00],\n",
       "        [ 2.4367e+00,  7.1028e-01,  9.8044e-01,  8.0047e-01,  3.0698e-01,\n",
       "         -1.9504e-01,  7.8403e-01, -2.8237e-01],\n",
       "        [ 3.5540e-01,  1.2432e+00,  4.7081e-01, -5.6149e-01,  4.5462e-01,\n",
       "          1.2924e+00, -4.9414e-01,  1.6068e-01],\n",
       "        [ 7.8756e-01, -3.9797e-01,  1.2849e+00,  6.8816e-01, -9.5165e-01,\n",
       "          6.3742e-01, -1.1232e+00,  6.9476e-01],\n",
       "        [-4.0477e-01,  2.0292e+00, -9.1634e-01, -2.9770e-01, -4.3459e-01,\n",
       "          1.8149e-01, -2.3945e+00, -6.0421e-01],\n",
       "        [-1.6590e+00, -1.0828e-01, -6.7962e-01,  5.2833e-01,  7.5799e-01,\n",
       "         -6.5054e-01,  1.3959e+00, -6.0351e-01],\n",
       "        [-1.0401e+00, -7.6047e-01,  1.5651e+00,  7.7088e-01,  1.4441e-01,\n",
       "         -6.9182e-01,  5.3926e-01,  7.3861e-01],\n",
       "        [-1.0469e+00,  5.9389e-01, -5.7997e-01,  5.5275e-01,  9.1372e-01,\n",
       "         -8.1557e-02,  7.9178e-01, -9.6606e-01],\n",
       "        [ 7.6475e-01,  1.1789e+00, -8.5303e-01,  1.0144e+00,  1.2873e+00,\n",
       "         -8.2248e-01,  1.4439e+00,  6.6027e-01],\n",
       "        [-8.1089e-01,  3.1177e-01, -6.2534e-01, -1.2993e-01, -1.4853e+00,\n",
       "         -1.1603e+00, -1.4973e+00,  2.6566e-01],\n",
       "        [ 8.0167e-01, -4.8626e-01, -1.3342e+00, -8.0339e-01,  1.0365e+00,\n",
       "          2.9417e-01,  8.5128e-01, -8.1400e-01],\n",
       "        [-6.6565e-02,  8.3240e-01,  1.3681e+00,  1.0218e-01,  1.8374e-01,\n",
       "         -1.7707e-01, -5.7584e-01, -1.1828e-01],\n",
       "        [-1.4954e+00,  1.7088e+00,  1.4803e+00,  8.2849e-01, -3.2937e-01,\n",
       "          5.6934e-01,  1.2621e-02, -4.7032e-01],\n",
       "        [ 6.7554e-02, -1.7405e+00, -1.1475e-01,  1.1880e+00, -2.8972e-01,\n",
       "          8.0296e-01,  3.9430e-01, -6.2576e-02],\n",
       "        [-6.9331e-01, -7.2546e-01, -4.8830e-01,  6.2309e-02,  4.7189e-01,\n",
       "          1.4871e-01,  5.5788e-01, -2.1367e+00],\n",
       "        [-2.1973e-01,  3.1133e-01,  1.0621e+00,  1.2037e+00, -1.1098e+00,\n",
       "          3.5656e-02,  2.2036e-01,  2.2568e-01],\n",
       "        [ 1.3836e+00,  4.7750e-01,  1.7793e-02,  2.2050e+00,  1.5088e+00,\n",
       "         -1.1315e-01, -7.6876e-01,  3.0338e-01],\n",
       "        [-3.0982e-01,  2.0231e+00,  1.6880e-01, -1.6898e+00,  8.0449e-01,\n",
       "         -1.4712e+00, -3.2483e-01, -6.5915e-01],\n",
       "        [ 6.5362e-01,  1.4871e-01, -8.5671e-01,  1.6117e+00, -1.8739e+00,\n",
       "         -1.1925e-01, -7.4037e-01, -1.3116e+00],\n",
       "        [ 4.9851e-01,  4.6701e-02, -5.7110e-01,  1.8026e+00, -9.2703e-01,\n",
       "         -7.4899e-01,  2.4812e-01, -1.3453e+00],\n",
       "        [-1.1940e+00, -2.1728e-01, -8.4112e-01,  2.3746e+00, -1.8555e+00,\n",
       "         -4.0450e-01, -2.5659e-01, -1.1746e-02],\n",
       "        [-2.6809e-02, -1.3239e-01,  1.1524e+00,  7.2463e-01,  1.0578e+00,\n",
       "          1.7804e-01,  8.7962e-01,  5.7622e-01],\n",
       "        [-2.3626e-01, -2.2480e+00,  9.7644e-01, -5.4168e-01,  1.5285e-01,\n",
       "         -4.7439e-01,  8.8017e-01, -2.2436e-01],\n",
       "        [ 1.5714e+00,  1.3977e+00, -7.6900e-01, -6.3079e-01, -8.2815e-01,\n",
       "         -2.7228e-01,  3.4209e-01,  5.6007e-01],\n",
       "        [-7.7601e-01,  1.7188e+00, -4.1324e-02, -4.9380e-01, -1.4454e+00,\n",
       "          3.8693e-01,  5.5041e-01,  1.4241e+00],\n",
       "        [ 1.8317e+00,  1.2584e+00,  1.6640e+00,  4.6144e-01,  7.4497e-01,\n",
       "         -8.1339e-01,  2.4855e+00,  1.3425e+00],\n",
       "        [-6.7268e-01,  1.7545e-02,  5.1528e-01, -1.0747e+00, -4.6608e-01,\n",
       "          4.9368e-01,  2.2259e+00,  1.0191e+00],\n",
       "        [-9.6790e-01,  2.2291e+00, -6.9354e-01, -1.0835e-01,  1.0002e+00,\n",
       "         -1.3162e+00,  1.8845e-01, -2.0109e+00],\n",
       "        [-1.3394e+00, -3.2915e-01,  3.6855e-01, -8.4160e-01, -1.2541e+00,\n",
       "          1.3459e+00,  5.2898e-01, -4.7457e-01],\n",
       "        [-4.9827e-01, -3.8671e-01, -4.8888e-01, -1.6823e+00,  2.8688e-01,\n",
       "          2.8646e-01,  2.4166e+00,  2.1137e-01],\n",
       "        [-3.9178e-01,  4.3932e-01,  1.1655e+00, -3.7642e-01, -3.2423e-01,\n",
       "         -1.3129e+00,  1.8049e-01,  6.5301e-01],\n",
       "        [ 1.2634e+00, -7.7947e-01, -5.4629e-01,  1.4666e+00,  7.1879e-01,\n",
       "          1.2230e+00, -1.5609e-01, -1.4709e-01],\n",
       "        [-1.4173e+00, -1.9259e-01, -1.2209e+00,  6.7653e-01, -1.9165e+00,\n",
       "          1.6441e+00,  2.5176e-01, -1.1950e-01],\n",
       "        [ 8.6931e-01, -1.7737e+00,  1.0929e+00,  3.2749e-01,  8.5645e-01,\n",
       "         -1.5553e+00, -1.0360e+00, -4.5105e-01],\n",
       "        [ 2.1496e-01,  6.4701e-01, -5.7703e-01,  2.1062e-01,  1.1257e+00,\n",
       "         -8.7203e-01, -1.8283e+00, -7.5294e-01],\n",
       "        [ 1.1143e+00,  1.1326e+00,  1.2412e+00,  1.3337e+00, -2.4310e-01,\n",
       "         -8.3012e-01,  7.3990e-02, -1.2888e+00],\n",
       "        [ 4.2166e-01, -8.7026e-01,  5.1485e-01, -1.3862e-01, -5.7546e-01,\n",
       "         -5.3593e-01, -3.9833e-01, -9.3850e-03],\n",
       "        [-1.1981e+00, -9.0968e-01,  1.0990e+00, -6.8505e-01, -1.9157e+00,\n",
       "         -2.2563e+00, -2.7190e+00, -1.9146e+00],\n",
       "        [ 7.2469e-01, -8.0443e-02,  1.7247e+00,  2.6945e-01, -5.9538e-01,\n",
       "         -4.5341e-02,  7.4357e-01,  7.7975e-01],\n",
       "        [-1.8948e+00,  5.8946e-01,  1.0293e-01, -7.9740e-01,  1.0950e+00,\n",
       "         -3.3931e-01,  4.6491e-01, -5.3636e-01],\n",
       "        [ 8.5490e-02, -1.6630e+00,  1.2528e-01,  1.3887e+00, -1.9098e-01,\n",
       "          2.7009e-01,  6.3682e-01,  2.3217e+00],\n",
       "        [ 5.4742e-01, -6.0311e-01, -5.0786e-01, -2.3953e-01, -7.8212e-01,\n",
       "         -1.4456e+00,  9.7432e-01,  4.4776e-01],\n",
       "        [ 2.8524e-01,  4.8758e-01, -1.7307e-01, -3.8231e-01,  2.7477e-01,\n",
       "         -1.9311e+00, -8.9030e-02,  7.1181e-01],\n",
       "        [ 6.7617e-01,  3.6332e-01, -3.7542e-01,  5.5436e-01,  1.3132e+00,\n",
       "         -1.1391e+00,  5.6184e-01, -2.2562e-01],\n",
       "        [ 6.8819e-01, -1.6070e-01,  3.4859e-01, -3.1809e-01,  5.8165e-01,\n",
       "         -5.3978e-01,  1.3640e+00,  2.5826e-02],\n",
       "        [-3.6062e-01, -2.5177e-01, -2.2906e-01,  1.3997e+00,  1.4963e+00,\n",
       "          1.4119e+00, -4.4950e-01,  5.2641e-01],\n",
       "        [-3.6285e-01,  8.4906e-01,  1.1536e+00,  1.2929e+00, -9.3954e-04,\n",
       "          6.6846e-01,  6.6010e-01, -1.1801e+00],\n",
       "        [-5.4054e-01, -3.1860e-01,  1.0890e+00, -4.5156e-02, -2.2335e-01,\n",
       "          2.6778e-01, -1.6429e+00, -1.4290e+00],\n",
       "        [ 1.5962e+00,  6.1992e-01,  2.9567e-01,  2.3402e+00,  6.9138e-01,\n",
       "         -9.6622e-01,  5.5750e-01,  1.1445e+00],\n",
       "        [ 7.0779e-01, -8.5780e-01,  8.7698e-01, -5.9555e-01, -1.8842e-01,\n",
       "         -9.1135e-02,  7.2733e-01, -9.5946e-01],\n",
       "        [-2.7683e-01,  2.7213e-01,  6.1586e-01, -1.2178e+00, -6.2631e-01,\n",
       "         -1.1151e+00, -9.6549e-02,  7.6821e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextChar(nn.Module):\n",
    "  def __init__(self, block_size, vocab_size, emb_dim, hidden_dims = [block_size * emb_dim, block_size * emb_dim]):\n",
    "    super().__init__()\n",
    "    self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "    self.lin1 = nn.Linear(block_size * emb_dim, hidden_dims[0])\n",
    "    self.lin2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "    self.lin3 = nn.Linear(hidden_dims[1], vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.emb(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = torch.sin(self.lin1(x))\n",
    "    x = torch.sin(self.lin2(x))\n",
    "    x = self.lin3(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate names from untrained model\n",
    "\n",
    "\n",
    "model = NextChar(block_size, len(vocab_dict), emb_dim).to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(4000002)\n",
    "def generate_name(model,sentence, itos, stoi, block_size, max_len=10):\n",
    "    original_sentence = sentence\n",
    "    if len(sentence) < block_size:\n",
    "        sentence = \" \" * (block_size - len(sentence)) + sentence\n",
    "    using_for_predicction = sentence[-block_size:].lower()\n",
    "    context = [stoi[word] for word in using_for_predicction]\n",
    "    prediction = \"\"\n",
    "    for i in range(max_len):\n",
    "        x = torch.tensor(context).view(1, -1).to(device)\n",
    "        y_pred = model(x)\n",
    "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
    "        ch = itos[ix]\n",
    "        prediction += ch\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "    return original_sentence + prediction\n",
    "\n",
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight torch.Size([65, 8])\n",
      "lin1.weight torch.Size([64, 64])\n",
      "lin1.bias torch.Size([64])\n",
      "lin2.weight torch.Size([64, 64])\n",
      "lin2.bias torch.Size([64])\n",
      "lin3.weight torch.Size([65, 64])\n",
      "lin3.bias torch.Size([65])\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(param_name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "import time\n",
    "# Mini-batch training\n",
    "batch_size = 4096\n",
    "print_every = 100\n",
    "elapsed_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.6574249267578125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m X[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mNextChar.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x))\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x))\n\u001b[0;32m---> 14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin3(x)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(10000):\n",
    "    start_time = time.time()\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        x = X[i:i+batch_size]\n",
    "        y = Y[i:i+batch_size]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    end_time = time.time()\n",
    "    elapsed_time.append(end_time - start_time)\n",
    "    if epoch % print_every == 0:\n",
    "        print(epoch, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is vannshckjour,\n",
      "His Hitherd. Year.\n",
      "\n",
      "QUEEN\n",
      "ISET:\n",
      "To qoer lay I wlom,\n",
      "A gongether in thoud is they it is nay s\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size,100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning knobs\n",
    "\n",
    "1. Embedding size\n",
    "2. MLP \n",
    "3. Context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NextChar(block_size, len(vocab_dict), emb_dim).to(device)\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
